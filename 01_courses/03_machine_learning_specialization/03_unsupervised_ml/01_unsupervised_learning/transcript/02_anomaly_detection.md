0:01Let's look at our second unsupervised learning algorithm.

0:06Anomaly detection algorithms look at an unlabeled dataset of normal events and thereby learns to detect or to raise a red flag for if there is an unusual or an anomalous event.

0:20Let's look at an example.

0:22Some of my friends were working on using anomaly detection to detect possible problems with aircraft engines that were being manufactured.

0:33When a company makes an aircraft engine, you really want that aircraft engine to be reliable and function well because an aircraft engine failure has very negative consequences.

0:45So some of my friends were using anomaly detection to check if an aircraft engine after it was manufactured seemed anomalous or if there seemed to be anything wrong with it.

0:58Here's the idea.

1:00After an aircraft engine rolls off the assembly line, you can compute a number of different features of the aircraft engine.

1:08So say feature X1 measures the heat generated by the engine, feature X2 measures the vibration intensity, and so on and so forth for additional features as well.

1:20But to simplify this slide a bit, I'm going to use just two features, X1 and X2, corresponding to the heat and the vibrations of the engine.

1:30Now, it turns out that aircraft engine manufacturers don't make that many bad engines.

1:37And so the easier type of data to collect would be if you have manufactured M aircraft engines to collect the features, X1 and X2, about how these M engines behave.

1:51And probably most of them are just fine, they're normal engines rather than ones with a defect or a flaw in them.

2:00And the anomaly detection problem is, after the learning algorithm has seen these M examples of how aircraft engines typically behave in terms of how much heat they generate and how much they vibrate,

2:15if a brand new aircraft engine were to roll off the assembly line, and if it had a new feature vector given by X tests, we'd like to know, does this engine look similar to ones that have been manufactured before?

2:32So is this probably okay? Or is there something really weird about this engine, which might cause this performance to be suspect, meaning that maybe we should inspect it even more carefully before we let it get shipped out and be installed in an airplane, and then hopefully nothing will go wrong with it.

2:51Here's how an anomaly detection algorithm works. Let me plot the examples X1 through XM over here via these crosses, where each cross, each data point in this plot corresponds to a specific engine with a specific amount of heat and a specific amount of vibrations.

3:11If this new aircraft engine, X tests, rolls off the assembly line, and if you were to plot these values of X1 and X2, and if it were here, you'd say, okay, that looks probably okay. It looks very similar to other aircraft engines. Maybe I don't need to worry about this one.

3:33But if this new aircraft engine has a heat and vibration signature that is, say, all the way down here, then this data point down here looks very different than the ones we saw up on top, and so we will probably say, boy, this looks like an anomaly. This doesn't look like the examples I've seen before. We'd better inspect this more carefully before we let this engine get installed on an airplane.

3:59How can you have an algorithm address this problem? The most common way to carry out anomaly detection is through a technique called density estimation.

4:13What that means is, when you're given your training set of these M examples, the first thing you do is build a model for the probability of X.

4:28In other words, the learning algorithm will try to figure out what are the values of the features X1 and X2 that have high probability, and what are the values that are less likely or have lower chance or lower probability of being seen in the dataset.

4:45In this example that we have here, I think it is quite likely to see examples in that little ellipse in the middle, so that region in the middle would have high probability. Maybe things in this ellipse have a little bit lower probability. Things in this ellipse or this oval have even lower probability, and things outside have even lower probability.

5:10The details of how you decide from the training set what regions are higher versus lower probability is something we'll see in the next few videos.

5:20Having learned a model for P of X, when you are given the new test example, X test, what you will do is then compute the probability of X test.

5:35If it is small, or more precisely, if it is less than some small number that I'm going to call epsilon, this is the Greek alphabet epsilon, which you should think of as a small number, which means that P of X is very small.

5:52In other words, the specific value of X that you saw for a certain user was very unlikely relative to other users that you have seen.

6:04But if P of X test is less than some small threshold, or some small number epsilon, we would raise a flag to say that this could be an anomaly.

6:14For example, if X test was all the way down here, the probability of an example landing all the way out here is actually quite low.

6:24Hopefully, P of X test for this value of X test would be less than epsilon, and so we would flag this as an anomaly.

6:32Whereas, in contrast, if P of X test is not less than epsilon, if P of X test is greater than or equal to epsilon, then we will say that it looks okay, this doesn't look like an anomaly.

6:46And that corresponds to if you had an example in here, say, where our model P of X will say that examples near the middle here, they're actually quite high probability.

6:56There's a very high chance that a new airplane engine will have features close to these inner ellipses, and so P of X test would be large for those examples, and we'll say it's okay and it's not an anomaly.

7:09Anomaly detection is used today in many applications. It is frequently used in fraud detection, where, for example, if you are running a website with many different features,

7:21if you compute Xi to be the features of user i's activities, and examples of features might include how often does this user log in and how many web pages do they visit,

7:34how many transactions are they making, or how many posts on the discussion forum are they making, to what is their typing speed, how many characters per second do they seem able to type.

7:48With data like this, you can then model P of X from data to model what is the typical behavior of a given user.

7:56In a common workflow of fraud detection, you wouldn't automatically turn off an account just because it seemed anomalous,

8:05but instead you may ask the security team to take a closer look, or put in some additional security checks, such as ask the user to verify their identity with a cell phone number, or ask them to pass a capture to prove that they're human, and so on.

8:22But algorithms like this are routinely used today to try to find unusual or maybe slightly suspicious activity, so they can more carefully screen those accounts to make sure there isn't something fraudulent.

8:36And this type of fraud detection is used both to find fake accounts, and this type of algorithm is also used frequently to try to identify financial fraud, such as if there's a very unusual pattern of purchases, then that may be something well worth a security team taking a more careful look at.

9:02Anomaly detection is also frequently used in manufacturing. You saw an example on the previous slide with aircraft engine manufacturing.

9:11But many manufacturers in multiple continents in many, many factories will routinely use anomaly detection to see if whatever they just manufactured, anything from an airplane engine, to a printed circuit board, to a smartphone, to a motor, to many, many things, to see if you've just manufactured a unit that somehow behaves strangely,

9:33because that may indicate that there's something wrong with your airplane engine, or printed circuit boards, or what have you, that might cause you to want to take a more careful look before you ship that object to the customer.

9:46It's also used to monitor computers in clusters and in data centers, where if Xi are the features of a certain machine i, such as if the features captured the memory usage, the number of disk accesses per second, CPU load, features can also be ratios, such as the ratio of CPU load to network traffic.

10:10Then if ever a specific computer behaves very differently than other computers, it might be worth taking a look at that computer to see if something is wrong with it, such as if it has had a hard disk failure, or a network card failure, or something's wrong with it, or if maybe it has been hacked into.

10:29Anomaly detection is one of those algorithms that is very widely used, even though you don't seem to hear people talk about it that much.

10:37I remember the first time I worked on a commercial application of anomaly detection was when I was helping a telco company put in place anomaly detection to see when any one of their cell towers was behaving in an unusual way, because that probably meant there was something wrong with the cell tower, and so they wanted to get a technician to take a look.

10:56So hopefully that helped more people get good cell phone coverage, and I've also used anomaly detection to find fraudulent financial transactions, and these days I often use it to help manufacturing companies find anomalous parts that they may have manufactured but should inspect more often.

11:16So it is a very useful tool to have in your tool chest, and in the next few videos we'll talk about how you can build and get these algorithms to work for yourself.

11:26In order to get anomalous detection algorithms to work, we'll need to use a Gaussian distribution to model the data, p of x.

11:36So let's go on to the next video to talk about Gaussian distributions.

---

0:02In order to apply anomaly detection, we're going to need to use the Gaussian distribution, which is also called the normal distribution.

0:11So when you hear me say either Gaussian distribution or normal distribution, they mean exactly the same thing.

0:18And if you've heard of the bell-shaped distribution, that also refers to the same thing.

0:24But if you haven't heard of the bell-shaped distribution, that's fine too.

0:28But let's take a look at what is the Gaussian or the normal distribution.

0:33Say X is a number, and if X is a random number, sometimes called a random variable, but if X can take on random values,

0:42and if the probability of X is given by a Gaussian or normal distribution with mean parameter mu and with variance sigma squared,

0:55what that means is that the probability of X looks like a curve that goes like this.

1:04The center or the middle of the curve is given by the mean, mu, and the standard deviation or the width of this curve is given by that variance parameter, sigma.

1:20Technically, sigma is called the standard deviation, and the square of sigma or sigma squared is called the variance of the distribution.

1:29And this curve here shows what is P of X or the probability of X.

1:35If you've heard of the bell-shaped curve, this is that bell-shaped curve because a lot of classic bells, say in towers, were kind of shaped like this, with the bell clapper hanging down here.

1:50And so the shape of this curve is vaguely reminiscent of the shape of the large bells that you will still find in some old buildings today.

2:00Better looking than my hand-drawn one, there's a picture of the Liberty Bell, and indeed the Liberty Bell's shape on top is a vaguely bell-shaped curve.

2:12If you're wondering what this P of X really means, here's one way to interpret it.

2:19It means that if you were to get, say, 100 numbers drawn from this probability distribution, and you were to plot a histogram of these 100 numbers drawn from this distribution,

2:32you might get a histogram that looks like this, and so it looks vaguely bell-shaped.

2:37And what this curve on the left indicates is not if you have just 100 examples, or 1,000, or 1,000,000, or 1,000,000, but if you had a practically infinite number of examples,

2:51and you were to draw a histogram of this practically infinite number of examples with a very, very fine histogram bin, then you end up with, essentially, this bell-shaped curve here on the left.

3:05The formula for P of X is given by this expression, P of X equals 1 over square root 2 pi.

3:15Pi here is that 3.14159, which is about 22 over 7, the ratio of a circle's diameter to circumference, times sigma, times e to the negative X minus mu, the mean parameter squared, divided by 2 sigma squared.

3:36And for any given value of mu and sigma, if you were to plot this function as a function of X, you get this type of bell-shaped curve that is centered at mu, and with the width of this bell-shaped curve being determined by the parameter sigma.

3:56Now, let's look at a few examples of how changing mu and sigma will affect the Gaussian distribution.

4:04First, let me set mu equals to 0 and sigma equals 1.

4:09Here's my plot of a Gaussian distribution with mean 0, mu equals 0, and standard deviation sigma equals 1.

4:19You notice that this distribution is centered at 0, and that is the standard deviation sigma is equal to 1.

4:28Now, let's reduce the standard deviation sigma to 0.5.

4:34If you plot the Gaussian distribution with mu equals 0 and sigma equals 0.5, it now looks like this.

4:43Notice that it's still centered at 0 because mu is 0, but it's become a much thinner curve because sigma is now 1.5.

4:54And you might recall that sigma, the standard deviation, is 0.5, whereas sigma squared is also called a variance, and so that's equal to 0.5 squared or 0.25.

5:08You may have heard that probabilities always have to sum up to 1, so that's why the area under the curve is always equal to 1,

5:16which is why when the Gaussian distribution becomes skinnier, it has to become taller as well.

5:23Let's look at another value of mu and sigma.

5:26Now I'm going to increase sigma to 2, so the standard deviation is 2, and the variance is 4.

5:35This now creates a much wider distribution because sigma here is now much larger,

5:43and because it's now a wider distribution, it's become shorter as well because the area under the curve is still equal to 1.

5:51And finally, let's try changing the mean parameter mu, and I'll leave sigma equals 0.5.

6:00In this case, the center of the distribution, mu, moves over here to the right,

6:07but the width of the distribution is the same as the one on top because the standard deviation is 0.5 in both of these cases on the right.

6:17So this is how different choices of mu and sigma affect the Gaussian distribution.

6:24When you're applying this to anomaly detection, here's what you have to do.

6:29You're given a data set of m examples, and here x is just a number, and here are parts of the training set with 11 examples.

6:41And what we have to do is try to estimate what are good choices for the mean parameter, mu,

6:48as well as for the variance parameter, sigma squared.

6:53And given a data set like this, it would seem that a Gaussian distribution may be looking like that,

7:01with a center here and a standard deviation kind of like that.

7:06This might be a pretty good fit to the data.

7:09The way you would compute mu and sigma squared mathematically is,

7:14our estimate for mu will be just the average of all the returning examples.

7:19So 1 over m times sum from i equals 1 through m of the values of the returning examples.

7:26And the value we would use to estimate sigma squared will be the average of the squared difference between the examples

7:34and that mu that you just estimated here on the left.

7:39It turns out that if you implement these two formulas in code with this value for mu and this value for sigma squared,

7:47then you pretty much get the Gaussian distribution that I hand drew on top.

7:51And this will give you a choice of mu and sigma for a Gaussian distribution,

7:56so that it kind of looks like the 11 training examples might have been drawn from this Gaussian distribution.

8:03If you've taken an advanced statistics class, you may have heard that these formulas for mu and sigma squared

8:10are technically called the maximum likelihood estimates for mu and sigma.

8:15And some statistics classes will tell you to use the formula 1 over m minus 1 instead of 1 over m.

8:23In practice, using 1 over m or 1 over m minus 1 makes very little difference.

8:29I always use 1 over m, but there are some other properties of dividing by m minus 1 that some statisticians prefer.

8:39But if you don't understand what I just said, don't worry about it.

8:43All you need to know is that if you set mu according to this formula and sigma squared according to this formula,

8:51you get a pretty good estimate of mu and sigma.

8:55And in particular, you get a Gaussian distribution that will be a plausible probability distribution

9:01in terms of what's the probability distribution that the training examples had come from.

9:07You can probably guess what comes next.

9:10If you were to get an example over here, then p of x is pretty high.

9:19Whereas if you were to get an example way out here, then p of x is pretty low,

9:25which is why we would consider this example okay, not really anomalous, not a lot like the other ones.

9:32Whereas an example way out here to be pretty unusual compared to the examples we've seen and therefore more anomalous.

9:40Because p of x, which is the height of this curve, is much lower over here on the left compared to this point over here closer to the middle.

9:49Now, we've done this only for when x is a number, as if you had only a single feature for your anomaly detection problem.

9:59For practical anomaly detection applications, you usually have a lot of different features.

10:05So you've now seen how the Gaussian distribution works if x is a single number.

10:12This corresponds to if, say, you had just one feature for your anomaly detection problem.

10:18But for practical anomaly detection applications, you will have many features, two or three or some even larger number n of features.

10:28Let's take what you saw for a single Gaussian and use it to build a more sophisticated anomaly detection algorithm that can handle multiple features.

10:37Let's go do that in the next video.

---

0:01Now that you've seen how the Gaussian or the normal distribution works for a single number,

0:07we're ready to build our anomaly detection algorithm. Let's dive in.

0:12You have a training set, X1 through Xm, where here each example X has n features.

0:20So each example X is a vector with n numbers.

0:24In the case of the airplane engine example, we had two features corresponding to the heat and the vibrations,

0:32and so each of these Xi's would be a two-dimensional vector, and n would be equal to 2.

0:38But for many practical applications, n can be much larger, and you might do this with dozens or even hundreds of features.

0:46Given this training set, what we would like to do is to carry out density estimation,

0:52and all that means is we will build a model or estimate the probability for P of X.

1:00What's the probability of any given feature vector?

1:05And our model for P of X is going to be as follows.

1:10X is a feature vector with values X1, X2, and so on, down to Xm.

1:19I'm going to model P of X as the probability of X1 times the probability of X2 times the probability of X3

1:29times the probability of Xn for the n features in the feature vectors.

1:38If you've taken an advanced class in probability and statistics before,

1:42you may recognize that this equation corresponds to assuming that the features X1, X2, and so on up to Xm are statistically independent,

1:53but it turns out this algorithm often works fine even if the features are not actually statistically independent.

2:00But if you don't understand what I just said, don't worry about it.

2:03Understanding statistical independence is not needed to fully complete this class

2:09and also be able to very effectively use the normal detection algorithm.

2:14Now, to fill in this equation a little bit more,

2:18we are saying that the probability of all the features of this vector features X is the product of P of X1 and P of X2 and so on up through P of Xn.

2:28And in order to model the probability of X1, say the heat feature in this example,

2:36we're going to have two parameters, mu1 and sigma1, or sigma squared 1.

2:43And what that means is we're going to estimate the mean of the feature X1 and also the variance of feature X1, and that will be mu1 and sigma1.

2:56To model P of X2, X2 is a totally different feature.

3:01Measuring the vibrations of the airplane engine, we're going to have two different parameters,

3:08which I'm going to write as mu2, sigma2 squared.

3:13And it turns out this will correspond to the mean or the average of the vibration feature and the variance of the vibration feature and so on.

3:23If you have additional features, mu3, sigma3 squared up through mun and sigma n squared.

3:33In case you're wondering why we multiply probabilities, maybe here's one example that could build intuition.

3:42Suppose for an aircraft engine, there's a one-tenth chance that it is really, really hot, unusually hot.

3:50And maybe there is a 1 in 20 chance that it vibrates really, really hot.

3:57Then what is the chance that it runs really, really hot and vibrates really, really hot?

4:02We're saying that the chance of that is one-tenth times 1 over 20, which is 1 over 200.

4:10So it's really, really unlikely to get an engine that both runs really hot and vibrates really hot.

4:16It's the product of these two probabilities.

4:19The chance of both of these things happening, we're saying, is the product of both of these probabilities.

4:26A somewhat more compact way to write this equation up here is to say that this is equal to the product from j equals 1 through n of p of xj,

4:41with parameters mu j and sigma squared j.

4:49And this symbol here is a lot like the summation symbol, except that whereas the summation symbol corresponds to addition,

4:58this symbol here corresponds to multiplying these terms over here for j equals 1 through n.

5:06So let's put it all together to see how you can build an anomaly detection system.

5:13The first step is to choose features xi that you think might be indicative of anomalous examples.

5:22Having come up with the features you want to use, you would then fit the parameters mu 1 through mu n

5:29and sigma squared 1 through sigma squared n for the n features in your data set.

5:37As you might guess, the parameter mu j will be just the average of xj of the feature j of all the examples in your training set,

5:48and sigma squared j will be the average of the squared difference between the j-th feature and the value mu j that you just computed up here on top.

6:01And by the way, if you have a vectorized implementation, you can also compute mu as the average of the training examples as follows,

6:12where here x and mu are both vectors, and so this would be the vectorized way of computing mu 1 through mu n all at the same time.

6:22And by estimating these parameters on your unlabeled training set, you've now computed all the parameters of your model.

6:31Finally, when you are given a new example, x test, or I'm just going to write the new example as x here,

6:40what you would do is compute p of x and see if it's large or small.

6:45So p of x, as you saw on the last slide, is the product from j equals 1 through n of the probability of the individual features,

6:53so p of xj with parameters mu j and sigma squared j.

6:59And if you substitute in the formula for this probability, you end up with this expression, 1 over root 2 pi sigma j of e to this expression over here.

7:12And so xj are the features, this is the j feature of your new example, mu j and sigma j are numbers or parameters you have computed in the previous step.

7:25And if you compute out this formula, you get some number for p of x.

7:32And the final step is to see if p of x is less than epsilon, and if it is, then you flag that it is an anomaly.

7:43One intuition behind what this algorithm is doing is that it will tend to flag an example as anomalous if one or more of the features are either very large or very small relative to what it has seen in the training set.

7:59So for each of the features xj, you're fitting a Gaussian distribution like this, and so if even one of the features of the new example was way out here, say,

8:12then p of xj would be very small, and if just one of the terms in this product is very small,

8:19then this overall product, when you multiply it together, will tend to be very small, and thus p of x will be small.

8:28And what anomaly detection is doing in this algorithm is a systematic way of quantifying whether or not this new example x has any features that are unusually large or unusually small.

8:43Now, let's take a look at what all this actually means on one example.

8:49Here's a dataset with features x1 and x2, and you notice that the features x1 take on a much larger range of values than the features x2.

9:02If you were to compute the mean of the features x1, you end up with 5, which is why mu1 is equal to 1,

9:10and it turns out that for this dataset, if you compute sigma1, it will be equal to about 2,

9:17and if you were to compute mu2, the average of the features on x2, the average is 3,

9:24and similarly, its variance, or standard deviation, is much smaller, which is why sigma2 is equal to 1.

9:33So that corresponds to this Gaussian distribution for x1 and this Gaussian distribution for x2.

9:43If you were to actually multiply p of x1 and p of x2, then you end up with this 3D surface plot for p of x,

9:52where at any point, the height of this is the product of p of x1 times p of x2 for the corresponding values of x1 and x2,

10:03and this signifies that values where p of x is higher are more likely, so values near the middle, kind of here, are more likely,

10:14whereas values far out here, like values out here, are much less likely, are much lower chance.

10:21Now, let me pick two test examples. The first one here, I'm going to write as xtest1, and the second one down here as xtest2,

10:34and let's see which of these two examples the algorithm will flag as anomalous.

10:40I'm going to pick the parameter epsilon to be equal to 0.02, and if you were to compute p of xtest1, it turns out to be about 0.04,

10:55and this is much bigger than epsilon, and so the algorithm will say, this looks okay, doesn't look like an anomaly,

11:02whereas in contrast, if you were to compute p of x for this point down here, corresponding to x1 equals about 8 and x2 equals about 0.5,

11:14kind of down here, then p of xtest2 is 0.0021, so this is much smaller than epsilon, and so the algorithm will flag this as a likely anomaly.

11:29So, pretty much as you might hope, it decides that xtest1 looks pretty normal, whereas xtest2, which is much further away than anything you've seen in the training set,

11:41looks like it could be an anomaly.

11:43So, you've seen the process of how to build an anomaly detection system, but how do you choose the parameter epsilon,

11:51and how do you know if your anomaly detection system is working well?

11:56In the next video, let's dive a little bit more deeply into the process of developing and evaluating the performance of an anomaly detection system.

12:05Let's go on to the next video.

---

0:01I'd like to share with you some practical tips for developing an anomaly detection system.

0:07One of the key ideas will be that if you can have a way to evaluate a system, even as it's being developed,

0:14you'll be able to make decisions and change a system and improve it much more quickly.

0:19Let's take a look at what that means.

0:21When you're developing a learning algorithm, say choosing different features or trying different values of the parameters like epsilon,

0:29making decisions about whether or not to change a feature in a certain way or to increase or decrease epsilon or other parameters,

0:37making those decisions is much easier if you have a way of evaluating the learning algorithm.

0:43This is sometimes called row number evaluation, meaning that if you can quickly change the algorithm in some way,

0:51such as change a feature or change a parameter, and have a way of computing a number that tells you if the algorithm got better or worse,

1:00then it makes it much easier to decide whether or not to stick with that change to the algorithm.

1:06This is how it's often done in anomaly detection, which is, even though we've mainly been talking about unlabeled data,

1:15I'm going to change that assumption a bit and assume that we have some labeled data, including just a small number usually of previously observed anomalies.

1:27So maybe after making airplane engines for a few years, you've just seen a few airplane engines that were anomalous.

1:36For examples that you know are anomalous, I'm going to associate a label y equals 1 to indicate it's anomalous.

1:46For examples that we think are normal, I'm going to associate a label y equals 0.

1:53The training set that the anomaly detection algorithm will learn from is still this unlabeled training set of x1 through xm.

2:04And I'm going to think of all of these examples as ones that we'll just assume are normal and not anomalous.

2:14So y is equal to 0.

2:16In practice, if a few anomalous examples were to slip into this training set, your algorithm will still usually do okay.

2:24To evaluate your algorithm, to come up with a way for you to have a real number evaluation, it turns out to be very useful if you have a small number of anomalous examples

2:40so that you can create a cross-validation set, which I'm going to denote xcv1, ycv1 through xcvmcv and ycvmcv.

2:50This is similar notation as you had seen in the second course of the specialization and similarly have a test set of some number of examples

3:02where both the cross-validation and the test sets hopefully include a few anomalous examples.

3:12In other words, the cross-validation and test sets will have a few examples with y equals 1 but also a lot of examples where y is equal to 0.

3:22And again, in practice, the anomaly detection algorithm will work okay if there are some examples that are actually anomalous but that were accidentally labeled with y equals 0.

3:34Let's illustrate this with the aircraft engine example.

3:38Let's say you have been manufacturing aircraft engines for years and so you've collected data from 10,000 goods or normal engines.

3:48But over the years, you have also collected data from 20 flawed or anomalous engines.

3:56Usually, the number of anomalous engines, that is y equals 1, will be much smaller.

4:02And so it would not be atypical to apply this type of algorithm with anywhere from, say, 2 to 50 known anomalies.

4:14We're going to take this data set and break it up into a training set, a cross-validation set, and a test set.

4:20Here's one example. I'm going to put 6,000 good engines into the training set.

4:26And again, if there are a couple anomalous engines that got slipped into this set, it's actually okay. I wouldn't worry too much about that.

4:36And then let's put 2,000 good engines and 10 of the known anomalies into the cross-validation set.

4:44And a separate 2,000 good and 10 anomalous engines into the test set.

4:50What you can do then is train the algorithm on the training set, fit the Gaussian distributions to these 6,000 examples.

5:01And then on the cross-validation set, you can see how many of the anomalous engines it correctly flags.

5:11And so, for example, you could use the cross-validation set to tune the parameter epsilon and set it higher or lower,

5:21depending on whether the algorithm seems to be reliably detecting these 10 anomalies without taking too many of these 2,000 good engines and flagging them as anomalies.

5:33And after you have tuned the parameter epsilon and maybe also added or subtracted or tuned the features xj,

5:42you can then take the algorithm and evaluate it on your test set to see how many of these 10 anomalous engines it finds,

5:51as well as how many mistakes it makes by flagging the good engines as anomalous ones.

5:57Notice that this is still primarily an unsupervised learning algorithm because the training set really has no labels,

6:07or they all have labels that we're assuming to be y equals 0.

6:11And so we learn from the training set by fitting the Gaussian distributions as you saw in the previous video.

6:18But it turns out, if you're building a practical anomaly detection system,

6:22having a small number of anomalies to use to evaluate the algorithm in your cross-validation and test sets is very helpful for tuning the algorithm.

6:33Because the number of flawed engines is so small, there's one other alternative that I often see people use for anomaly detection,

6:43which is to not use a test set, but to have just a training set and a cross-validation set.

6:50So in this example, you would still train on 6,000 good engines, but take the remainder of the data,

6:56the 4,000 remaining good engines, as well as all the anomalies, and put them in the cross-validation set.

7:02And you would then tune the parameters epsilon and add or subtract features xj to try to get it to do as well as possible as evaluated on the cross-validation set.

7:13If you have very, very few flawed engines, so if you had only two flawed engines,

7:20then this really makes sense to put all of that in the cross-validation set.

7:25And you just don't have enough data to create a totally separate test set that is distinct from your cross-validation set.

7:32The downside of this alternative here is that after you've tuned your algorithm,

7:37you don't have a fair way to tell how well this will actually do on future examples because you don't have a test set.

7:46But when your data set is small, especially when the number of anomalies you have in your data set is small,

7:52this might be the best alternative you have.

7:54And so I see this done quite often as well when you just don't have enough data to create a separate test set.

8:01And if this is the case, just be aware that there's a higher risk that you would have over-fit some of your decisions around epsilon

8:10and choice of features and so on to the cross-validation set.

8:13And so its performance on real data in the future may not be as good as you were expecting.

8:21Now, let's take a closer look at how to actually evaluate the algorithm on your cross-validation sets or on the test set.

8:29Here's what you do. You would first fit the model P of X on the training set.

8:35So this is the 6,000 examples of good engines.

8:38Then on any cross-validation or tested example X, you would compute P of X and you would predict Y equals 1,

8:49that is, anomalous, if P of X is less than epsilon.

8:52And you predict Y is zero if P of X is greater than or equal to epsilon.

8:59And so based on this, you can now look at how accurately this algorithm's predictions on the cross-validation or test set

9:09matches the labels Y you have in the cross-validation or the test sets.

9:15In the third week of the second course, we had had a couple of optional videos on how to handle highly skewed data distributions

9:25where the number of positive examples, Y equals 1, can be much smaller than the number of negative examples where Y equals zero.

9:34And this is the case as well for many anomaly detection applications where the number of anomalies in your cross-validation set is much smaller.

9:44In our previous example, we had maybe 10 positive examples and 2,000 negative examples

9:51because we had 10 anomalies and 2,000 normal examples.

9:55If you saw those optional videos, you may recall that we saw it can be useful to compute things like the true positive,

10:02false positive, false negative, and true negative rates or to compute precision recall or F1 score

10:08and that these are alternative metrics to classification accuracy that could work better when your data distribution is very skewed.

10:17So if you saw that video, you might consider applying those types of evaluation metrics as well

10:23to tell how well your learning algorithm is doing at finding that small handful of anomalies or positive examples

10:31amidst this much larger set of negative examples of normal plane engines.

10:37If you didn't watch that video, don't worry about it. It's okay.

10:41The intuition I hope you get is to use the cross-validation set to just look at how many anomalies it's finding

10:48and also how many normal engines it is incorrectly flagging as an anomaly

10:53and then to just use that to try to choose a good choice for the parameter epsilon.

10:59So you find that the practical process of building an anomaly detection system is much easier

11:07if you actually have just a small number of labeled examples of known anomalies.

11:13Now, this does raise a question. If you have a few labeled examples, should you still be using an unsupervised learning algorithm?

11:21Why not take those labeled examples and use a supervised learning algorithm instead?

11:26In the next video, let's take a look at a comparison between anomaly detection and supervised learning

11:33and when you might prefer one over the other. Let's go on to the next video.

---

0:02When you have a few positive examples with y equals 1 and a large number of negative

0:08examples, say y equals 0, when should you use anomaly detection and when should you

0:13use supervised learning?

0:15The decision is actually quite subtle in some applications, so let me share with you some

0:20thoughts and some suggestions for how to pick between these two types of algorithms.

0:26An anomaly detection algorithm will typically be the more appropriate choice when you have

0:31a very small number of positive examples, 0 to 20 positive examples is not uncommon,

0:40and a relatively large number of negative examples with which to try to build a model

0:47for p of x, where you recall that the parameters for p of x are learned only from the negative

0:54examples, and this much smaller set of positive examples is only used in your cross-validation

1:00set and test sets for parameter tuning and for evaluation.

1:04In contrast, if you have a larger number of positive and negative examples, then supervised

1:10learning might be more applicable.

1:13Now, even if you have only 20 positive training examples, it might be okay to apply a supervised

1:22learning algorithm, but it turns out that the way anomaly detection looks at the dataset

1:27versus the way supervised learning looks at the dataset are quite different.

1:32Here's the main difference, which is that if you think there are many different types

1:38of anomalies or many different types of positive examples, then anomaly detection might be

1:45more appropriate.

1:47When there are many different ways for an aircraft engine to go wrong, and if tomorrow

1:52there may be a brand new way for an aircraft engine to have something wrong with it, then

1:58your 20, say, positive examples may not cover all of the ways that an aircraft engine could

2:05go wrong.

2:06That makes it hard for any algorithm to learn from the small set of positive examples what

2:11the anomalies, what the positive examples look like, and future anomalies may look nothing

2:17like any of the anomalous examples we've seen so far.

2:21If you believe this to be true for your problem, then I would gravitate toward using an anomaly

2:27detection algorithm, because what anomaly detection does is it looks at the normal examples,

2:33that is, the y equals zero negative examples, and just tries to model what they look like.

2:39And anything that deviates a lot from normal, it flags as an anomaly, including if there's

2:44a brand new way for an aircraft engine to fail that had never been seen before in your

2:49dataset.

2:50In contrast, supervised learning has a different way of looking at the problem.

2:55When you apply supervised learning, ideally, you would hope to have enough positive examples

3:00for the algorithm to get a sense of what the positive examples are like.

3:04And with supervised learning, we tend to assume that future positive examples are likely to

3:10be similar to the ones in the training set.

3:14Let me illustrate this with one example.

3:17If you are using a system to find, say, financial fraud, there are many different ways, unfortunately,

3:25that some individuals are trying to commit financial fraud.

3:29And unfortunately, there are new types of financial fraud attempts every few months

3:35or every year.

3:36And what that means is that because they keep on popping up completely new and unique forms

3:42of financial fraud, anomaly detection is often used to just look for anything that's

3:48different than transactions we've seen in the past.

3:52In contrast, if you look at the problem of email spam detection, well, there are many

3:58different types of spam email, but even over many years, spam emails keep on trying to

4:04sell similar things or get you to go to similar websites and so on.

4:10Spam email that you will get in the next few days is much more likely to be similar

4:15to spam emails that you have seen in the past.

4:18So that's why supervised learning works well for spam because it's trying to detect more

4:25of the types of spam emails that you have probably seen in the past in your training

4:30set.

4:31Whereas, if you're trying to detect brand new types of fraud that have never been seen

4:35before, then anomaly detection may be more applicable.

4:39So let's go through a few more examples.

4:42We have already seen fraud detection being one use case of anomaly detection, although

4:48supervised learning is used to define previously observed forms of fraud, and we've seen email

4:55spam classification typically being addressed using supervised learning.

5:00You've also seen the example of manufacturing, where you may want to find new previously

5:07unseen defects, such as if there are brand new ways for an aircraft engine to fail in

5:13the future that you still want to detect, even if you don't have any positive example

5:17like that in your training set.

5:20It turns out that in manufacturing, supervised learning is also used to find defects, more

5:25for finding known and previously seen defects.

5:29For example, if you are a smartphone maker, you're making cell phones, and you know that

5:35occasionally your machine for making the case of the smartphone will accidentally scratch

5:40the cover.

5:41So scratches are a common defect on smartphones, and so you can get enough training examples

5:49of scratched smartphones corresponding to a label y equals one, and just train the system

5:55to decide if a new smartphone that you just manufactured has any scratches in it.

6:00And the difference is, if you just see scratched smartphones over and over, and you want to

6:05check if your phones are scratched, then supervised learning works well.

6:10Whereas if you suspect that there are going to be brand new ways for something to go wrong

6:13in the future, then anomaly detection will work well.

6:17Some other examples, you've heard me talk about monitoring machines in the data center,

6:23especially the machines in the hack.

6:24It can behave differently in a brand new way, unlike any previous way it has behaved.

6:29So that would feel more like an anomaly detection application.

6:34In fact, one theme is that many security-related applications, because hackers are often finding

6:40brand new ways to hack into systems, many security-related applications will use anomaly

6:45detection.

6:47Whereas returning to supervised learning, if you want to learn to predict the weather,

6:52well, there's only a handful types of weather that you typically see.

6:57Is it sunny, rainy, is it going to snow?

6:59And so because you see the same upper labels over and over, weather prediction would tend

7:05to be a supervised learning task.

7:07Or if you want to use the symptoms of the patient to see if the patient has a specific

7:12disease that you've seen before, then that would also tend to be a supervised learning

7:16application.

7:18So I hope that gives you a framework for deciding when you have a small set of positive examples,

7:23as well as maybe a large set of negative examples, whether to use anomaly detection or supervised

7:29learning.

7:30Anomaly detection tries to find brand new positive examples that may be unlike anything

7:35you've seen before.

7:37Whereas supervised learning looks at your positive examples and tries to decide if a

7:41future example is similar to the positive examples that you've already seen.

7:46Now it turns out that when building an anomaly detection algorithm, the choice of features

7:52is very important.

7:54And when building anomaly detection systems, I often spend a bit of time trying to tune

7:59the features I use for the system.

8:01In the next video, let me share some practical tips on how to tune the features you feed

8:06to your anomaly detection algorithm.

---
0:02When building an anomaly detection algorithm, I found that choosing a good choice of features

0:08turns out to be really important.

0:11In supervised learning, if you don't have the features quite right, or if you have a

0:15few extra features that are not relevant to the problem, that often turns out to be okay

0:20because the algorithm has the supervised signal, that is, enough labels Y for the algorithm

0:26to figure out what features to ignore, or how to rescale a feature, and to take the

0:31best advantage of the features you do give it.

0:35But for anomaly detection, which runs or learns just from unlabeled data, it's harder for

0:41the algorithm to figure out what features to ignore.

0:44So I've found that carefully choosing the features is even more important for anomaly

0:49detection than for supervised learning approaches.

0:53Let's take a look in this video at some practical tips for how to tune the features for anomaly

0:58detection to try to get you the best possible performance.

1:01One step that can help your anomaly detection algorithm is to try to make sure the features

1:07you give it are more or less Gaussian.

1:11And if your features are not Gaussian, sometimes you can change it to make it a little bit

1:17more Gaussian.

1:18Let me show you what I mean.

1:21If you have a feature X, I will often plot a histogram of the feature, which you can

1:29do using the Python command plt.his.

1:34You see this in the practice lab as well, in order to look at the histogram of the data.

1:41This distribution here looks pretty Gaussian, so this would be a good candidate feature

1:46if you think this is a feature that helps distinguish between anomalies and normal

1:51examples.

1:52But quite often, when you plot a histogram of your features, you may find that a feature

1:59has a distribution like this.

2:01This does not at all look like that symmetric bell-shaped curve.

2:07When that is the case, I would consider if you can take this feature X and transform

2:16it in order to make it more Gaussian.

2:19For example, maybe if you were to compute the log of X and plot a histogram of log of

2:26X, it would look like this, and this looks much more Gaussian.

2:32If this feature was feature X1, then instead of using the original feature X1, which looks

2:39like this on the left, you might instead replace that feature with log of X1 to get this distribution

2:47over here.

2:48Because when X1 is made more Gaussian, when anomaly detection models p of X1 using a Gaussian

2:57distribution like that is more likely to be a good fit to the data.

3:02Other than the log function, other things you might do is, given a different feature

3:07X2, you may replace it with X2 log of X2 plus 1.

3:13This would be a different way of transforming X2.

3:17And more generally, log of X2 plus C would be one example of a formula you can use to

3:24change X2 to try to make it more Gaussian.

3:29Or for a different feature, you might try taking the square root, or really, the square

3:33root of X cubed is X3 to the power of 1 half, and you may change that exponentiation term.

3:41So for a different feature X4, you might use X4 to the power of 1 third, for example.

3:47So when I'm building an anomaly detection system, I'll sometimes take a look at my features

3:52and if I see any that are highly non-Gaussian by plotting a histogram, I might choose transformations

3:59like these or others in order to try to make it more Gaussian.

4:03It turns out a larger value of C will end up transforming this distribution less.

4:11But in practice, I just try a bunch of different values of C and then try to pick one that

4:17looks better in terms of making the distribution more Gaussian.

4:22Now let me illustrate how I actually do this in a Jupyter Notebook.

4:27So this is what the process of exploring different transformations in the features might look like.

4:33When you have a feature X, you can plot a histogram of it as follows.

4:39It actually looks like this is a pretty coarse histogram.

4:44Let me increase the number of bins in my histogram to 50, so bins equals 50.

4:51There's more histogram bins.

4:53Oh, and by the way, if you want to change the color, you can also do so as follows.

5:00And if you want to try a different transformation, you can try, for example, to plot X square

5:08root of X, so X to the power of 0.5 with, again, 50 histogram bins, in which case it

5:16might look like this.

5:18And this actually looks somewhat more Gaussian, but not perfectly.

5:23And let's try a different parameter.

5:25So let me try to the power of 0.25.

5:31Maybe I adjusted a little bit too far to the 0.4.

5:34That looks pretty Gaussian.

5:36So one thing you could do is replace X with X to the power of 0.4.

5:42So you would set X to be equal to X to the power of 0.4 and just use the value of X in

5:51your training process instead.

5:53Well, let me show you another transformation.

5:56Here I'm going to try taking the log of X.

5:59So log of X, let's plot it with 50 bins, but I'm going to use the numpy log function as

6:09follows.

6:10It turns out you get an error because it turns out that X in this example has some values

6:17that are equal to 0 and, well, log of 0 is negative infinity, it's not defined.

6:23So common trick is to add just a very tiny number there.

6:29So X plus 0.001 becomes non-negative.

6:33And so you get a histogram that looks like this.

6:36And if you want the distribution to look more Gaussian, you can also play around with

6:40this parameter to try to see if there's a value that causes the data to look more symmetric

6:48and maybe look more Gaussian as follows.

6:52And just as I'm doing right now in real time, you can see that you can very quickly change

6:58these parameters and plot the histogram in order to try to take a look and try to get

7:04something a bit more Gaussian than was the original data X that you saw in this histogram

7:13up above.

7:14If you read the machine learning literature, there are some ways to automatically measure

7:19how close these distributions are to Gaussians, but I've found that in practice, it doesn't

7:24make a big difference.

7:25If you just try a few values and pick something that looks right to you, that will work well

7:30for our practical purposes.

7:32So by trying things out in a Jupyter notebook, you can try to pick a transformation that

7:39makes your data more Gaussian.

7:41And just as a reminder, whatever transformation you apply to the training set, please remember

7:48to apply the same transformation to your cross-validation and test set data as well.

7:53Other than making sure that your data is approximately Gaussian, after you've trained your anomaly

8:00detection algorithm, if it doesn't work that well on your cross-validation set, you can

8:07also carry out an error analysis process for anomaly detection.

8:13In other words, you can try to look at where the algorithm is not yet doing well, where

8:17it's making errors, and then use that to try to come up with improvements.

8:24So as a reminder, what we want is for p of x to be large for normal examples x, so greater

8:32than or equal to epsilon, and p of x to be small, or less than epsilon, for the anomalous

8:39examples x.

8:40When you've learned the model p of x from your unlabeled data, the most common problem

8:46that you may run into is that p of x is comparable in value, say is large for both normal and

8:53for anomalous examples.

8:55As a concrete example, if this is your data set, you might fit that Gaussian to it, and

9:03if you have an example in your cross-validation set or test set that is over here, that is

9:09anomalous, then this has a pretty high probability, and in fact it looks quite similar to the

9:14other examples in your training set.

9:17And so even though this is an anomaly, p of x is actually pretty large, and so the

9:24algorithm will fail to flag this particular example as an anomaly.

9:28In that case, what I would normally do is try to look at that example and try to figure

9:36out what is it that made me think it's an anomaly, even if this feature, x1, took on

9:43values similar to other training examples.

9:47And if I can identify some new feature, say x2, that helps distinguish this example from

9:57the normal examples, then adding that feature can help improve the performance of the algorithm.

10:03Here's a picture showing what I mean.

10:05If I can come up with a new feature, x2, say I'm trying to detect fraudulent behavior,

10:12and if x1 is the number of transactions they make, maybe this user looks like they're

10:19making similar transactions as everyone else.

10:23But if I discover that this user has some insanely fast typing speed, and if I were

10:29to add a new feature, x2, that is the typing speed of this user.

10:35And if it turns out that when I plot this data using the old feature, x1, and this new

10:40feature, x2, causes x2 to stand out over here, then it becomes much easier for the

10:47anomaly detection algorithm to recognize that x2 is an anomalous user.

10:52Because when you have this new feature, x2, the learning algorithm may fit a Gaussian

10:58distribution that assigns high probability to points in this region, a bit lower in this

11:03region, and a bit lower in this region.

11:07And so this example, because of the very anomalous value of x2, becomes easier to

11:13detect as an anomaly.

11:16So just to summarize, the development process I'll often go through is to train a model

11:22and then to see what anomalies in the cross-validation set the algorithm is failing to detect, and

11:29then to look at those examples to see if that can inspire the creation of new features that

11:35would allow the algorithm to spot that that example takes on unusually large or unusually

11:42small values on the new features, so that it can now successfully flag those examples

11:47as anomalies.

11:49Just as one more example, let's say you're building an anomaly detection system to monitor

11:54computers in a data center to try to figure out if a computer may be behaving strangely

12:00and deserves a closer look, maybe because of a hardware failure or because it's been

12:05hacked into or something.

12:07So what you like to do is to choose features that might take on unusually large or small

12:11values in the event of an anomaly.

12:15You might start off with features like x1 is the memory use, x2 is number of disk accesses

12:20per second, then the CPU load, and the volume of network traffic.

12:25And if you train the algorithm, you may find that it detects some anomalies but fails to

12:33detect some other anomalies.

12:35In that case, it's not unusual to create new features by combining old features.

12:42So for example, if you find that there's a computer that is behaving very strangely,

12:49but neither is CPU load nor network traffic, is that unusual?

12:54But what is unusual is it has a really high CPU load while having a very low network traffic

13:00volume.

13:02If you're running a data center that streams videos, then computers may have high CPU load

13:08and high network traffic or low CPU load and no network traffic.

13:12But what's unusual about this one machine is it has very high CPU load despite a very

13:16low traffic volume.

13:17In that case, you might create a new feature, x5, which is a ratio of CPU load to network

13:23traffic, and this new feature would help the anomaly detection algorithm flag future examples

13:29like the specific machine you may be seeing as anomalous.

13:34Or you can also consider other features like the square of the CPU load divided by the

13:42network traffic volume, and you can play around with different choices of these features in

13:48order to try to get it so that p of x is still large for the normal examples, but it becomes

13:55small in the anomalies in your cross-validation set.

14:00So that's it.

14:01Thanks for sticking with me to the end of this week.

14:03I hope you enjoyed hearing about both clustering algorithms and anomaly detection algorithms,

14:10and that you also enjoy playing with these ideas in the practice labs.

14:16Next week, we'll go on to talk about recommender systems.

14:20When you go to a website and it recommends products or movies or other things to you,

14:25how does that algorithm actually work?

14:28This is one of the most commercially important algorithms in machine learning that gets talked

14:34about surprisingly little, but next week, we'll take a look at how these algorithms

14:39work so that you understand the next time you go to a website and it recommends something

14:43to you, maybe how that came about, as well as you'll be able to build other algorithms

14:48like that for yourself as well.

14:50So have fun with the labs, and I look forward to seeing you next week.